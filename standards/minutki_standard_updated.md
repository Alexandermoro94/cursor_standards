# Minutki Standard

updated: 3 Dec 2025, 15:00 CET by AI Assistant  
based on: JTBD Scenarium Standard 11 May 2025, 08:15 CET

## Изменения в версии от 3 декабря 2025:
- Обновлены требования к Output: финальный артефакт с указанием ссылки, структуры, столбцов (для таблиц)
- Переработаны требования к Definition of Done: добавлен чеклист проверки output с описанием параметров и ожидаемых значений, интеграция с принципами from_the_end.md
- Обновлена структура Контекста: описание ситуации → проблема
- Добавлено уточнение в раздел "Активности": задачи по генерации идей для обмена опытом относятся к этому разделу
- Обновлен пример задачи с новой структурой Output и DoD
- Обновлен чеклист проверки качества с учетом новых требований

## Изменения в версии от 8 октября 2025:
- Обновлен список разделов: "Постинг" заменен на "Активности" с добавлением разборов кейсов участников
- Добавлен новый раздел "Монетизация" для задач по воронке подключения участников, подписок и донатов
- Переработана структура подпунктов задач: убран дедлайн из DoD, добавлены Output, Ответственный, Артефакты
- Добавлены требования к Definition of Done (фиксировать только важные требования, опускать технические нюансы)
- Обновлен пример задачи с новой структурой
- Уточнено оформление раздела "На будущее" (можно оформлять тезисами)

## Цель стандарта

Данный документ будет использоваться менеджерами для подготовки минуток после звонков, где по разделам будут описаны задачи с DoD, последовательностью задач, блокерами и дополнительными комментариями.

## Структура минуток

### 3.1 Соблюдается иерархия

Сперва разделы, внутри разделов отдельные задачи (тикеты), внутри задачи подпункты:
- Контекст (обязателен)
- Definition of Done
- Output
- Ответственный
- Дедлайн
- Артефакты

#### Список текущих разделов (верхний уровень):

1. Организационные вопросы — доступы, структура, расписание, регламенты, встречи, документация и т.п.
2. Монетизация — задачи касающиеся воронки по подключению новых участников, подписок и донатов.
3. Активности — контент-план, подготовка/оформление/публикация материалов, каналы, расписание, теги, метрики CTR/ER, разборы кейсов участников, генерация идей для обмена опытом.
4. Эдвайзеринг — клиентские задачи, рекомендации, подготовка/проведение сессий, сценарии участников (без публикаций).
5. Дополнительно — прочие задачи, не попавшие в основные разделы.
6. На будущее — бэклог идей и задач на последующие итерации (пункты в этом разделе можно оформлять не по шаблону оформления задач, а просто тезисом. Например "новый титул за принятие участие в активности").

### 3.2 Пример оформленной задачи (шаблон, числовой формат)

```
1. Организационные вопросы

1.1. Настройка ИИ-агента для загрузки материалов по NDA в именную папку

Контекст:
Ситуация: Когда пользователь хочет попасть в эдвайзеринг, он отправляет на почту сканы своего паспорта и подписанного NDA. Сейчас эти материалы сохраняются вручную, что занимает время и может привести к ошибкам при поиске документов конкретного пользователя.

Проблема: Отсутствует автоматизация процесса сохранения NDA, что увеличивает время обработки заявок и риск потери документов.

Definition of Done:
- [ ] В n8n рамках проекта heroesofconversion.space@gmail.ru настроен флоу
- [ ] Этот флоу при получении триггера (получение письма с сканами) сохраняет их в именной папке
- [ ] Проведено тестирование на 5+ реальных письмах с NDA
- [ ] Проверка Output: ссылка на папку с NDA работает, папка содержит сканы паспорта и подписанного NDA для каждого отправителя
- [ ] Gap Analysis: сравнение с ручным процессом (Expected: автоматическое сохранение, Actual: [заполняется при проверке], Gap: [заполняется при проверке], Decision: [fix/ok], Evidence: ссылки на тестовые письма и результаты)

Output:
Финальный артефакт: автоматически созданная именная папка отправителя в общей папке с NDA
Ссылка: [ссылка на папку с NDA]
Структура: для каждого отправителя создается отдельная папка с именем отправителя, внутри которой находятся:
- Скан паспорта (файл с расширением .pdf или .jpg)
- Подписанный NDA (файл с расширением .pdf)
Параметры проверки:
- Имя папки соответствует имени отправителя из письма
- В папке присутствуют оба файла (паспорт и NDA)
- Файлы доступны для просмотра и скачивания

Ответственный: Лера

Дедлайн: 9 октября 2025

Артефакты:
- Ссылка на папку с NDA
- Ссылка на проект в n8n
```

Пример для задачи с таблицей:

```
3. Активности

3.1. Таблица анализа кастдевов (3 разговора)

Контекст:
Ситуация: Проведены три интервью по кастдеву для понимания потребностей участников сообщества. Результаты интервью записаны в разных форматах и не структурированы.

Проблема: Без структурирования результатов невозможно провести анализ и выявить общие паттерны потребностей участников.

Definition of Done:
- [ ] Для каждого разговора заполнены поля: потребность, сценарий, желаемый ауткам, как закрывает сейчас, какие проблемы
- [ ] Таблица приведена к единому формату
- [ ] Проверка Output: ссылка на таблицу работает, все столбцы заполнены, данные структурированы
- [ ] Artefact Comparison Challenge: сравнение с эталоном (шаблон анализа кастдевов) - структура эталона соответствует, критерии эталона выполнены
- [ ] Gap Analysis: Expected: таблица с 3 строками, все столбцы заполнены, формат соответствует шаблону; Actual: [заполняется при проверке]; Gap: [заполняется при проверке]; Decision: [fix/ok]; Evidence: ссылка на таблицу и шаблон
- [ ] Все три разговора проанализированы и задокументированы

Output:
Финальный артефакт: таблица "НОС Custdev November 2025" с результатами анализа 3 разговоров
Ссылка: [ссылка на таблицу]
Структура таблицы (столбцы):
- Разговор № (номер разговора: 1, 2, 3)
- Потребность (описание потребности участника)
- Сценарий (описание сценария использования)
- Желаемый ауткам (что хочет получить участник)
- Как закрывает сейчас (текущее решение проблемы)
- Какие проблемы (выявленные проблемы текущего решения)
Параметры проверки:
- Все 3 строки заполнены (по одной на каждый разговор)
- Все столбцы содержат данные (нет пустых ячеек)
- Данные структурированы и понятны
- Формат соответствует шаблону анализа кастдевов

Ответственный: Лера

Дедлайн: 3 декабря 2025

Артефакты:
- Ссылка на таблицу "НОС Custdev November 2025"
- Шаблон анализа кастдевов
```

### 3.3 Дополнительные требования

#### Контекст

- **Структура контекста:**
  1. **Ситуация** — описание текущего состояния, процесса или обстоятельств
  2. **Проблема** — какая проблема возникла или может возникнуть в описанной ситуации

- **Контекст должен говорить о связке с outcome из карты целей** — как текущая задача связана с ним
- **Контекст должен быть сформулирован через JTBD**, используя паттерн "Роль-Контекст-Потребность" (в описании ситуации)

#### Output

- **Output должен содержать:**
  - Описание финального артефакта (что конкретно получится)
  - Ссылку на артефакт (если применимо)
  - Структуру артефакта (для документов, таблиц, процессов)
  - Столбцы (для таблиц) с описанием назначения каждого столбца
  - Параметры проверки (что должно быть в артефакте, какие значения ожидаются)

- **Для таблиц обязательно указывать:**
  - Название таблицы
  - Список столбцов с описанием
  - Ожидаемое количество строк (если известно)
  - Формат данных в каждом столбце

- **Для документов/файлов указывать:**
  - Название документа
  - Структуру (разделы, подразделы)
  - Формат файла

- **Для процессов/систем указывать:**
  - Описание процесса
  - Входные и выходные данные
  - Ключевые этапы

#### Definition of Done

- **Definition of Done должен содержать:**
  - Чеклист выполнения ключевых требований задачи
  - Чеклист проверки Output с описанием параметров и ожидаемых значений
  - Gap Analysis (сравнение с эталоном или предыдущим состоянием, если применимо)
  - Критерии проверки качества результата

- **Принципы составления DoD (на основе from_the_end.md):**
  - Фиксировать только самые важные требования
  - Опускать технические нюансы
  - Включать проверку соответствия Output ожиданиям
  - Указывать параметры проверки с конкретными ожидаемыми значениями
  - При необходимости включать сравнение с эталоном (Artefact Comparison Challenge)

- **Artefact Comparison Challenge (если применимо):**
  При наличии эталона для сравнения в DoD должно быть указано:
  - **Эталонный артефакт:** ссылка на идеальный пример или описание эталона
  - **Структура эталона:** описание структуры и содержания эталона
  - **Критерии эталона:** конкретные требования к качеству, которым должен соответствовать результат
  - **Контекст эталона:** условия и ограничения, при которых эталон применим

- **Gap Analysis (если применимо):**
  При сравнении с эталоном или предыдущим состоянием в DoD должно быть указано:
  - **Expected:** конкретное описание ожидаемого результата
  - **Actual:** фактический результат после выполнения (заполняется при проверке)
  - **Gap:** конкретные различия между ожидаемым и фактическим (заполняется при проверке)
  - **Decision:** решение (fix/ok) после анализа gap (заполняется при проверке)
  - **Evidence:** ссылки на скриншоты, тесты и результаты проверки (заполняется при проверке)

- **Административные пункты не включать в чеклист качества** (например, "ссылка добавлена в репозиторий материалов"). Такие действия оформлять как отдельные задачи проекта "Организация" либо как артефакты в DoD без чекбоксов качества.

Правила форматирования (обязательно):
- Использовать числовую иерархию разделов: 1., 1.1., 1.1.1 при необходимости.
- В качестве верхнего уровня использовать разделы: «Организационные вопросы», «Монетизация», «Активности», «Эдвайзеринг», «Дополнительно», «На будущее» (при наличии соответствующих задач).
- Не использовать эмодзи в заголовках и тексте минуток.
- Не писать раздел «Блокеры и вопросы», если блокеров нет.
- Не использовать горизонтальные разделители '---'.
- Минимизировать пустые строки (не более одной подряд).
- В Definition of Done фиксировать только самые важные требования, опускать технические нюансы.

---

## Чеклист проверки качества минуток

Чеклист сформирован на основе требований к структуре минуток (пункты 3.1-3.3) и имеет форму вопросов для запуска feedback loop:

### Структурные требования (3.1)

- [ ] **Соблюдена ли иерархия проектов → тикеты → подзадачи?**
  **Feedback Loop**: "Могу ли я показать четкую структуру минуток? Если нет, как ее улучшить?"

- [ ] **Все ли разделы заполнены для каждой задачи?**
  **Feedback Loop**: "Есть ли у каждой задачи контекст, DoD, Output, ответственный, дедлайн и артефакты? Если нет, какие добавить?"

- [ ] **Правильно ли распределены задачи по проектам?**
  **Feedback Loop**: "Соответствуют ли задачи описанию проектов? Если нет, как перераспределить?"

### Содержательные требования (3.3)

- [ ] **Структурирован ли контекст: ситуация → проблема?**
  **Feedback Loop**: "Содержит ли контекст описание ситуации и проблемы? Если нет, как структурировать?"

- [ ] **Связан ли контекст каждой задачи с outcome из карты целей?**
  **Feedback Loop**: "Могу ли я объяснить связь каждой задачи с бизнес-целями? Если нет, как установить связь?"

- [ ] **Применен ли JTBD-подход для формулировки контекста?**
  **Feedback Loop**: "Сформулирован ли контекст через паттерн 'Роль-Контекст-Потребность'? Если нет, как переформулировать?"

- [ ] **Содержит ли Output описание финального артефакта с ссылкой, структурой, столбцами (для таблиц)?**
  **Feedback Loop**: "Можно ли по описанию Output понять, что конкретно получится? Есть ли ссылка, структура, столбцы? Если нет, что добавить?"

- [ ] **Содержит ли Output параметры проверки с ожидаемыми значениями?**
  **Feedback Loop**: "Понятно ли, какие значения должны быть в артефакте? Если нет, какие параметры добавить?"

- [ ] **Содержит ли DoD чеклист проверки Output с описанием параметров и ожидаемых значений?**
  **Feedback Loop**: "Можно ли по DoD проверить качество результата? Есть ли описание параметров и ожидаемых значений? Если нет, что добавить?"

- [ ] **Включен ли в DoD Artefact Comparison Challenge (если применимо)?**
  **Feedback Loop**: "Есть ли сравнение с эталонным артефактом? Указаны ли эталонный артефакт, структура эталона, критерии эталона, контекст эталона? Если применимо, как добавить?"

- [ ] **Включен ли в DoD Gap Analysis (если применимо)?**
  **Feedback Loop**: "Есть ли сравнение результата с эталоном или предыдущим состоянием? Указаны ли Expected, Actual, Gap, Decision, Evidence? Если применимо, как добавить?"

- [ ] **Содержит ли DoD только самые важные требования без технических нюансов?**
  **Feedback Loop**: "Сфокусирован ли DoD на ключевых требованиях? Нет ли избыточных технических деталей? Если есть, как упростить?"

- [ ] **Установлены ли реалистичные дедлайны?**
  **Feedback Loop**: "Реалистичны ли установленные дедлайны? Если нет, как их скорректировать?"

### Процессные требования

- [ ] **Выявлены ли все блокеры и зависимости?**
  **Feedback Loop**: "Зафиксированы ли все препятствия и зависимости? Если нет, какие добавить?"


- [ ] **Покрывает ли Definition of Done все аспекты задачи?**
  **Feedback Loop**: "Достаточно ли пунктов в DoD для проверки качества? Если нет, что добавить?"

- [ ] **Исключены ли административные пункты из Definition of Done?**
  **Feedback Loop**: "Не попали ли в DoD пункты вроде 'ссылка добавлена в репозиторий'? Если да — вынести их в проект 'Организация' или в артефакты."

*Этот стандарт следует использовать совместно с JTBD Scenarium Standard для соблюдения принципов формулировки контекста задач и со стандартом from_the_end.md для составления Definition of Done с проверкой Output.*
